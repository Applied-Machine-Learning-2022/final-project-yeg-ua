{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yolov5 DeepSort Pytorch tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Applied-Machine-Learning-2022/final-project-yeg-ua/blob/ellion0/Yolov5_DeepSort_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIGuIpRFAo18"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone repo, install dependencies and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taGCP-gCgqX8",
        "\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JQRVPMtA9Cr"
      },
      "source": [
        "# Download data\n",
        "\n",
        "Get test video from repo and extract the first 2 seconds of it "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Acf_nRZ7yS6",
      },
      "source": [
        "%cd /content/Yolov5_StrongSORT_OSNet\n",
        "\n",
        "# get yolov5m model trained on the crowd-human dataset\n",
        "!wget -nc https://github.com/mikel-brostrom/Yolov5_StrongSORT_OSNet/releases/download/v.2.0/crowdhuman_yolov5m.pt -O /content/Yolov5_StrongSORT_OSNet/yolov5/crowdhuman_yolov5m.pt\n",
        "\n",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Yolov5_StrongSORT_OSNet\n",
            "File ‘/content/Yolov5_StrongSORT_OSNet/yolov5/crowdhuman_yolov5m.pt’ already there; not retrieving.\n",
            "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqIP5shr9HQd"
      },
      "source": [
        "## Run inference on video\n",
        "\n",
        "The ``cv2.imshow()`` and ``cv.imshow()`` functions from the [opencv-python](https://github.com/skvark/opencv-python) package are incompatible with Jupyter notebook; see https://github.com/jupyter/notebook/issues/3935. \n",
        "\n",
        "Hence we chose to save it to file in this notebook. Locally you can use the ``--show-vid`` flag in order visualize the tracking in real-time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yEraJfKhBku",
      },
      "source": [
        "!python track.py --yolo-weights /content/Yolov5_StrongSORT_OSNet/yolov5/crowdhuman_yolov5m.pt --classes 0 --strong-sort-weights osnet_x0_25_msmt17.pt --source out.mp4 --save-vid"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "strong_sort/deep/reid/torchreid/metrics/rank.py:12: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
            "  'Cython evaluation (very fast so highly recommended) is '\n",
            "Model: osnet_x0_25\n",
            "- params: 203,568\n",
            "- flops: 82,316,000\n",
            "Successfully loaded pretrained weights from \"osnet_x0_25_msmt17.pt\"\n",
            "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n",
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd-CFrVGBoEU"
      },
      "source": [
        "# Show results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ObuFb7dBwxK"
      },
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        " \n",
        "def show_video(video_path, video_width = 600):\n",
        "   \n",
        "  video_file = open(video_path, \"r+b\").read()\n",
        " \n",
        "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "  return HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")\n",
        " \n",
      "outputs": []
    }
  ]
}